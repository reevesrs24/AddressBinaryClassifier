{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iHDPFA6aT8wL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import string\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import unicodedata\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htH7EllWeBRo"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WX9TO0IfEvk6"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, fc_hidden_dim):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_dim\n",
        "    self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, batch_first=True)\n",
        "    self.fc1 = nn.Linear(hidden_dim, fc_hidden_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(fc_hidden_dim, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    out, hidden = self.lstm(input.view(1, 1, -1), hidden)\n",
        "    out = self.fc1(hidden[0])\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out.view(1, -1), hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return (torch.zeros(1, 1, self.hidden_size).cuda(), torch.zeros(1, 1, self.hidden_size).cuda())\n",
        "    #return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdjMREIh5OYi",
        "outputId": "cb200445-6349-4994-f549-5abcf01a41f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235000\n",
            "('732 24TH AVE E Days Creek PR 72134', 1)\n"
          ]
        }
      ],
      "source": [
        "inputs = []\n",
        "\n",
        "df = pd.read_csv('address_dataset.csv')\n",
        "for index, row in df.iterrows():\n",
        "  inputs.append((row['text'], row['label']))\n",
        "\n",
        "\n",
        "random.shuffle(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ueV28RIl97T",
        "outputId": "40d056a5-f755-4cc7-8192-a2ed6729ee13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ #.,;'\n",
            "58\n",
            "Slusarski\n",
            "26\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.]])\n",
            "t-12\n",
            "torch.Size([3, 1, 58])\n"
          ]
        }
      ],
      "source": [
        "all_letters = string.ascii_letters + \" #.,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, \n",
        "# thanks to https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "def normalize(line):\n",
        "    if type(line) != str:\n",
        "      return \" \"\n",
        "    line = line.replace(',', '')\n",
        "    line = line.lower()\n",
        "    return line\n",
        "\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "def lineToTensor(line):\n",
        "    line = normalize(line)\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrHZLtFD-nrT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hl8BXHo1rB_U"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "n_hidden = 128\n",
        "n_hidden_2 = 64\n",
        "\n",
        "lstm = LSTM(n_letters, n_hidden, n_hidden_2)\n",
        "lstm.to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(lstm.parameters(), lr=0.0001)\n",
        "\n",
        "def train(batch):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for b in batch:\n",
        "      text, label = b\n",
        "      text_tensor = lineToTensor(text)\n",
        "      label_tensor = torch.tensor([[label]], dtype=torch.float).cuda()\n",
        "      #label_tensor = torch.tensor([[int(label)]], dtype=torch.float)\n",
        "\n",
        "\n",
        "      hidden = lstm.init_hidden()\n",
        "      for i in range(text_tensor.size()[0]):\n",
        "          output, hidden = lstm(text_tensor[i].cuda(), hidden)\n",
        "          #output, hidden = lstm(text_tensor[i], hidden)\n",
        "\n",
        "      loss = criterion(output.cuda(), label_tensor)\n",
        "      #loss = criterion(output, label_tensor)\n",
        "\n",
        "      loss.backward(retain_graph=True)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    return output, loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPjQDEfrrHym",
        "outputId": "2d5fb461-990a-45f5-c183-86cc08b6f0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6917230486869812\n",
            "Loss: 0.45231312884157526\n",
            "Loss: 0.21092578204121673\n",
            "Loss: 0.09671823677397333\n",
            "Loss: 0.10218168177560437\n",
            "Loss: 0.026723304077226204\n",
            "Loss: 0.04888286434760084\n",
            "Loss: 0.006745311136190594\n",
            "Loss: 0.01188792362472077\n",
            "Loss: 0.007520549940030946\n",
            "Loss: 0.026105942666538567\n",
            "Loss: 0.003887763871682239\n",
            "Loss: 0.04231106172205102\n",
            "Loss: 0.04422939063763323\n",
            "Loss: 0.03803845986992263\n",
            "Loss: 0.01669081492731857\n",
            "Loss: 0.03042502304759347\n",
            "Loss: 0.027267929140741217\n",
            "Loss: 0.01976485121291506\n",
            "Loss: 0.08951455326959615\n"
          ]
        }
      ],
      "source": [
        "# Keep track of losses for plotting\n",
        "all_losses = []\n",
        "batches = 2500\n",
        "\n",
        "lstm.train()\n",
        "\n",
        "train_size = int(0.8 * len(inputs))\n",
        "test_size = len(inputs) - train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(inputs, [train_size, test_size])\n",
        "\n",
        "total_loss = 0\n",
        "train_dataset = list(train_dataset)\n",
        "\n",
        "for i in range(batches):\n",
        "    batch = random.sample(train_dataset, 64)\n",
        "    output, loss = train(batch)\n",
        "    total_loss += loss\n",
        "\n",
        "    if i == 0:\n",
        "      all_losses.append(loss)\n",
        "      print(\"Loss: {}\".format(loss))\n",
        "\n",
        "    if i % 250 == 0 and i != 0:\n",
        "      avg_loss = total_loss / 250\n",
        "      print(\"Loss: {}\".format(avg_loss))\n",
        "      all_losses.append(avg_loss)\n",
        "      total_loss = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(line_tensor):\n",
        "    hidden = lstm.init_hidden()\n",
        "    \n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = lstm(line_tensor[i], hidden)\n",
        "\n",
        "    return output\n",
        "\n",
        "def test(test_inputs):\n",
        "\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for test in test_inputs:\n",
        "\n",
        "      text, label = test\n",
        "      output = evaluate(lineToTensor(text).cuda())\n",
        "      #output = evaluate(lineToTensor(text))\n",
        "\n",
        "      pred = 1 if output.item() >= 0.5 else 0\n",
        "\n",
        "      if pred == label:\n",
        "        correct += 1\n",
        "  \n",
        "  print(\"Accuracy: {}\".format(correct / len(test_dataset)))\n",
        "\n",
        "\n",
        "test(test_dataset)"
      ],
      "metadata": {
        "id": "7fSi9xiWROs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a901287-c0e3-4c92-d896-07e38e087781"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9942553191489362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7-yriU7EyJsJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "0418b63a-1e67-4c9f-ee0f-adda0b67dec6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2ec1946169c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'all_losses' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rJ3LA7-2zo5w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "5304f610-5fd7-45a7-efa6-aa2067c462cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dfasdfa sfdasfds afas\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dda53fc601bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfasdfa sfdasfds afas'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hey hey my my rock n roll will never die'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1600, Washington DC 20500'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-dda53fc601bc>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(input_line)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlineToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#output = evaluate(lineToTensor(input_line))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "def predict(input_line):\n",
        "    print(\"{}\".format(input_line))\n",
        "    with torch.no_grad():\n",
        "        output = evaluate(lineToTensor(input_line).cuda())\n",
        "        #output = evaluate(lineToTensor(input_line))\n",
        "        print(output.item())\n",
        "\n",
        "predict('dfasdfa sfdasfds afas')\n",
        "predict('Hey hey my my rock n roll will never die')\n",
        "predict('1600, Washington DC 20500')\n",
        "predict('Pennsylvania Avenue, Washington 1600')\n",
        "predict('1600 Pennsylvania Avenue, Washington DC')\n",
        "predict('1600 Pennsylvania Avenue, Washington DC 20500')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QnCUxugEyxJj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}